---
layout: post
category: openstack
title: cinder快照/备份技术解析
tagline: by 噜噜噜
tags: 
  - openstack snapshot
published: true
---



<!--more-->

### 一、cinder所提供的几种备份快照技术

**注意：cinder提供的这几种功能都要后端存储的支持，如Ceph**

- Replication（复制）

- Snapshot（快照）

- Backup（备份）：

  

### 二、Snapshot快照技术

#### 1、分类

按照 SNIA （存储网络行业协会）的定义, 快照有 **全量快照和增量快照** 两种类型, 其中又各自使用了不同的快照技术:

- 全量快照
  - **镜像分离 (Split Mirror)**
- 增量快照
  - **写时拷贝 (Copy-On-Write)**
  - **写时重定向 (Redirect-On-Write)**--------逐渐成为快照技术的主流

#### 2、全量快照

使用**镜像分离快照技术**

①在到达预设的快照时间点之前，为源数据卷创建一个完整的镜像卷。源数据卷和镜像卷组成一个镜像对。

②每次写入数据到磁盘时，都会往源数据盘和镜像卷中同时写入一份数据。

③在到达快照的时间点时，镜像对中的镜像卷停止写入操作并快速脱离镜像对（几毫秒），转换为快照卷。



优点:

- 数据隔离性好, 使离线访问数据成为可能
- 简化了恢复、复制或存档一块硬盘上的所有数据的过程
- 操作的时间非常短, 仅仅是断开镜像卷对所需的时间, 通常只有几毫秒, 这样小的备份窗口几乎不会对上层应用造成影响

缺点：

-  缺乏灵活性, 无法在任意时间点为任意的数据卷建立快照
- 需要一个或者多个与源数据卷容量相同的镜像卷, 占用了大量存储空间
- 写数据时同时写两份, 对写入性能影响比较大

#### 3、增量快照

##### 3.1 cow写时复制快照技术

使用**COW写时拷贝快照技术**：原理就是利用数据的指针地址

![è¿éåå¾çæè¿°](https://img-blog.csdn.net/20170324145956629?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvSm1pbGs=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![](https://s3.ax1x.com/2021/02/04/y3PCy8.png)

①为源数据卷生成一个数据指针表 【COW这种技术会为每个卷创建一张数据指针表保存源数据卷中的所有数据的物理地址】

②创建快照（动作）

③拷贝一份数据指针表的副本，这里称为快照卷数据指针表

④生成快照卷（有一定预留空间）

⑤源数据卷中的原始数据收到了更新的操作

⑥将源数据卷中的原始数据拷贝到快照卷的预留空间中，下一次针对这个位置的写操作不会再进行拷贝。（要保留最原始的数据）

⑦更新快照指针表（更新的部分为将上步中拷贝的数据，将指针表 中的地址变更到快照卷中预留空间地址）

⑧更新源数据卷中的原始数据

⑨不断的重复5~8步，直到下一次快照



优点：

- COW 在进行快照操作之前, 不会占用任何的存储资源, 也不会影响系统性能
- 创建快照时由于快照卷与源数据卷通过各自的指针表共享同一份物理数据, 而不需要进行全量拷贝所以快照创建速度非常快, 可以瞬间完成.
- COW 创建快照时产生的备份窗口长度与源数据卷的 Size 成线性比例, 一般为几秒钟, 相比全量快照要长, 但快照卷占用的存储空间却大大减少

缺点：

- COW 因为创建快照后会的每次写入操作都需要先将源数据卷中的原始数据拷贝到快照卷中才能开始写入源数据卷, 所以会**降低源数据卷的写性能**.
- 如果对同一源数据卷做了多次快照之后, 写性能将会更加低下 （**更新数据时，每个快照都需要拷贝一份源数据到快照卷中**）
- 如果拷贝到快照卷中的数据量超过了保留空间, 快照就将失效.

##### 3.2 ROW写时重定向快照技术

**只改变源数据卷指针表中的地址，不改变快照指针表中的地址。因此恢复的时候更加方便**

![è¿éåå¾çæè¿°](https://img-blog.csdn.net/20170324164352508?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvSm1pbGs=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

如上图, Vd 表示源数据卷, Snap 表示快照卷, 当源数据卷创建一个快照时, Vd 与 snap 是一致的. 如果在创建快照之后, 对源数据卷的数据进行了更新操作的话, 并不会像 COW 似得直接修改源数据卷原始数据, 而是再开辟一个新的空间用于存放用于更新原始数据的新的数据. 具体步骤如下:

ROW的实现原理与COW 非常相似，区别在于ROW对原始数据卷的首次写操作，会将新数据重定向到预留的快照卷中，而非COW一般会使用新数据将原始数据覆盖。所以，ROW快照中的原始数据依旧保留在源数据卷中，并且为了保证快照数据的完整性，在创建快照时，源数据卷状态会由读写变成只读的

![](https://s3.ax1x.com/2021/02/04/y3tHeS.png)

①为源数据卷生成一个数据指针表 【COW这种技术会为每个卷创建一张数据指针表保存源数据卷中的所有数据的物理地址】

②创建快照（动作）

③拷贝一份数据指针表的副本，这里称为快照卷数据指针表

④生成快照卷（有一定预留空间）

⑤源数据卷中的原始数据收到了更新的操作

⑥新数据会直接被写入到快照卷中

⑦**更新源数据指针表的记录，指向新数据所在的快照地址**

⑧不断的重复5~7步，直到下一次快照

`由此可见：`

**更新源数据卷中的原始数据时, 将源数据卷数据指针表中的被更新原始数据指针重定向到新的存储空间**. 所以由此至终, 快照卷的数据指针表和其对应的数据是没有被改变过的. **恢复快照的时候, 只需要按照快照卷数据指针表来进行寻址就可以完成恢复了.**



优点：

- 源数据卷创建快照后的写操作会被重定向, 所有的写 IO 都被重定向到新卷中, 而所有快照卷数据(旧数据)均保留在只读的源数据卷中. 这样做的好处是更新源数据卷只需要一次写操作, 解决了 COW 写两次的性能问题。所以 ROW 最明显的优势就是**不会降低源数据卷的写性能**.

缺点：

- ROW 的快照卷数据指针表保存的是源数据卷的原始副本, 而源数据卷数据指针表保存的则是更新后的副本, 这导致在删除快照卷之前需要将快照卷数据指针表指向的数据同步至源数据卷中，不然源数据会丢失掉
- 当创建了多个快照后, 会产生一个快照链, 使原始数据的访问、快照卷和源数据卷数据的追踪以及快照的删除将变得异常复杂
- 因为源数据卷数据指针指向的数据会很快的被重定向分散, 所以 ROW 另一个主要缺点就是**降低了读性能**(局部空间原理).



**在分布式存储设备上, ROW 的连续读写的性能会比 COW 更加好**. 一般而言, 读写性能的瓶颈都在磁盘上. 而分布式存储的特性是数据越是分散到不同的存储设备中, 系统性能越高. 所以 ROW 的源数据卷重定向分散性反而带来了好处. 因此, ROW 逐渐成为了业界的主流，但是要注意快照多了会产生slow.



### 三、Replication

`该功能用的人不多`

Replication通过在两个Volume（卷）之间创建一个Session（会话），并进行数据同步，这两个Volume可以处于同一台存储阵列中，也可以处于两个异地的存储阵列中，同时只有一个提供生产服务，当提供生产服务的Primary Volume发生故障时，立即切换至备用的Secondary Volume，从而保证业务的连续性

Replication根据数据同步的方式分为Sync（同步）与Async（异步）两种模式。Sync模式下，数据在写入Primary Volume与Secondary Volume后才可用；Async模式反之。因此，只有Sync Replication可以提供RPO=0的保障

#### 1、cinder的支持

Cinder从Juno版开始支持Replication，目前API已发展至v2.1版本

`操作指南：`

①首先需要创建支持Replication的volume type

```
cinder type-create replication-type 
cinder type-key replication-type set replication_enabled=True
```

②使用上步中的类型创建相应的卷

```
cinder create --volume-type replication_type --name vol001 100
```

③发生故障时对指定的cinder backend执行故障切换操作

```
cinder failover-host [--backend_id <backend-id>] <hostname>  ##backend-id：是将要切换成的ID  hostname：是被取代的故障volume节点
```



#### 2、ceph的支持

[]: https://www.sohu.com/a/147092935_734726

### 四、Backup

**提供 Volume 的备份功能，支持将 Volume 备份到对象存储中（e.g. Swift、Ceph、IBM TSM、NFS），也支持从备份 Restore 成为 Volume**。**当然也可以本非到RBD存储中。**

#### 1、和快照的区别

- snapshot依赖源volume，不能独立存在；而backup不依赖vilume，即便源volume不存在了，仍可以restroe
- snapsot与源volume通常存放在一起，由同一个volume provider管理；backup存放在独立的备份设备中，有自己的备份方案和实现
- backup具有容灾功能；而snapshot则提供volume provider内便捷的回溯功能

#### 2、ceph的backup支持

cinder 备份提供了三种驱动服务： Ceph，TSM，Swift 其中默认备份驱动服务为swift

cinder 驱动服务的配置在cinder.conf文件中

```
backup_driver=cinder.backup.drivers.swift  ##使用swift的备份驱动
backup_driver = cinder.backup.drivers.ceph.CephBackupDriver  ##使用ceph备份驱动
```

关于ceph的相关配置

[官网配置]: https://docs.openstack.org/cinder/victoria/configuration/block-storage/backup/ceph-backup-driver.html

```
backup_ceph_conf=/etc/ceph/ceph.conf
backup_ceph_user = cinder-backup
backup_ceph_chunk_size = 134217728
backup_ceph_pool = backups
backup_ceph_stripe_unit = 0
backup_ceph_stripe_count = 0
```

**判断源卷是否为RBD卷，如果源卷为RBD卷，则使用增量备份，否则使用全量备份**，这是对于ceph的块存储和对象存储/文件存储来区分。

①cinder-volume使用非RBD作为backend

​	这种情况下比较简单，并且仅支持**全量备份**。在创建备份时，首先创建一个base backup image，然后每次从源卷读入chunk_size（即backup_ceph_chunk_size，默认是128MB）大小的数据，写入到backup image，直到把整个源卷都复制完。注意，这里不支持对chunk的压缩。因为volume上的数据都会写入到创建的这个backup image上去，也就是说volume和backup是一对一的，因此也不需要metadata文件

②cinder-volume使用RBD作为backend

​	在这种情况下，即cinder-volume和cinder-backup都是用rbd作为backend，是支持**增量备份**的。增量备份的实现完全依赖于ceph处理差量文件的特性，所谓ceph处理差量文件的能力，即ceph可以将某个rbd image不同时刻的状态进行比较，并且将其差量导出成文件。另外，ceph也可以将这个差量文件导入到某个image中

**熟悉ceph的话，应该知道ceph rbd的export-diff，import-diff 功能：**

- export-diff ：将某个 rbd image 在两个不同时刻的数据状态比较不同后导出补丁文件。
- import-diff :将某个补丁文件合并到某个 rbd image 中。

ceph 增量备份就是基于这两个基本功能，详细命令示例可以参考[rbd的增量备份和恢复](http://www.zphj1987.com/2016/06/22/rbd的增量备份和恢复/)



