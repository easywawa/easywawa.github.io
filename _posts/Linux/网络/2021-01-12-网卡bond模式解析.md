---
layout: post
category: Linux
title: 网卡bond模式解析
tagline: by 噜噜噜
tags: 
  - 网络
published: true
---



<!--more-->

### 一、bonding的原理

在正常情况下，网卡只接收目的硬件地址(MAC Address)是自身Mac的以太网帧，对于别的数据帧都滤掉，以减轻驱动程序的负担。但是网卡也支持另外一种被称为**混杂promisc的模式**，可以接 收网络上所有的帧，比如说tcpdump，就是运行在这个模式下。**bonding也运行在这个模式下，而且修改了驱动程序中的mac地址，将两块网卡的 Mac地址改成相同**，可以接收特定mac的数据帧。然后把相应的数据帧传送给bond驱动程序处理

`bonding只能提供链路监测，即从主机到交换机的链路是否接通。如果只是交换机对外的链路down掉了，而交换机本身并没有故障，那么bonding会认为链路没有问题而继续使用`

### 二、Bonding的模式

##### 1、mode0:round robin  轮询策略

- Ø **负载均衡**---所有链路处于负载均衡状态，轮询方式往每条链路发送报文，基于per packet方式发送。传输数据包顺序是依次传输（即：第1个包走eth0，下一个包就走eth1....一直循环下去，直到最后一个传输完毕）。在一个双网卡绑定的机器上ping一个地址，你会发现两个网卡都有流量发出。负载到两条链路上，说明是基于per packet方式进行轮询发送。
- Ø **容错能力**---这模式的特点增加了带宽，同时支持容错能力，当有链路出问题，会把流量切换到正常的链路上。
- Ø **性能问题**---一个连接或者会话的数据包如果从不同的接口发出的话，中途再经过不同的链路，在客户端很有可能会出现数据包无序到达的问题，而无序到达的数据包需要重新要求被发送，这样网络的吞吐量就会下降。**mode0在大压力的网络传输下，性能增长的并不是很理想。**
- Ø **交换机做聚合端口**-----由于绑定的所有网卡的IP都被修改为同一个MAC地址。此时交换机收到发往该MAC地址的数据包时，将不知道从对应的哪个端口转发该数据，为了解决交换机的这个问题，交换机应做端口绑定，将数据发往逻辑聚合端口，之后由聚合端口从多个端口转发数据

##### 2、mode1:active-backup 主备策略

- Ø **容错能力**---只有一个slave是激活的(active)。也就是说同一时刻**只有一个网卡处于工作状态，其他的slave都处于备份状态**，只有在当前激活的slave故障后才有可能会变为激活的(active)。
- Ø **无负载均衡-**--此算法的优点是可以提供高网络连接的可用性，但是它的资源利用率较低，只有一个接口处于工作状态，在有 N 个网络接口的情况下，资源利用率为1/N。
- Ø **无需交换机支持**--- MAC地址是外部可见得，从外面看来，bond的MAC地址是唯一的，以避免switch(交换机)发生混乱。

##### 3、mode2:load balancing (xor)  异或策略

`缺省的策略为：(源MAC地址 XOR 目标MAC地址) % slave数量。 # XOR为异或运算，值不同时结果为1，相同为0`

`可以通过**xmit_hash_policy**选项设置传输策略`

- Ø **负载均衡和容错能力**---基于指定的传输HASH策略传输数据包。
- Ø **性能问题**---该模式将限定流量，以保证到达特定对端的流量总是从同一个接口上发出。既然目的地是通过MAC地址来决定的，因此该模式在“本地”网络配置下可以工作得很好。**如果所有流量是通过单个路由器（比如 “网关”型网络配置，只有一个网关时，源和目标mac都固定了，那么这个算法算出的线路就一直是同一条，那么这种模式就没有多少意义了。），那该模式就不是最好的选择。**
- Ø **交换机做聚合口**---这模式是通过源和目标mac做hash因子来做xor算法来选路的。

##### 4、mode3:fault-tolerance (broadcast)  广播策略

这种模式的特点是一个报文会复制两份往bond下的两个接口分别发送出去，当有对端交换机失效，我们感觉不到任何downtime，但此法过于浪费资源；不过这种模式有很好的容错机制。**此模式适用于金融行业，因为他们需要高可靠性的网络，不允许出现任何问题**

##### 5、mode4:lacp链路聚合控制协议

`IEEE 802.3ad协议的特点：`

- 自动聚合：它在交换机中自动创建链路聚合，“链路聚合控制协议”自动通知交换机应该聚集哪些端口

- 帧按顺序传递：802.3ad标准也要求帧按顺序（一定程度上）传递，因此通常单个连接不会看到包的乱序

- 共享速率：要求所有设备在聚合操作时，要在同样的速率和双工模式

- 带宽限制：任何连接都不能使用多于一个接口的带宽

  

外出流量的slave选举是基于传输hash策略，该策略可以通过xmit_hash_policy选项从缺省的XOR策略改变到其他策略。需要注意的是，并不是所有的传输策略都是802.3ad适应的，尤其考虑到在802.3ad标准43.2.4章节提及的**包乱序问题**。不同的实现可能会有不同的适应性



  **必要条件：**

-   ethtool支持获取每个slave的速率和双工设定；
-   switch(交换机)支持IEEE 802.3ad Dynamic link aggregation。
-   大多数switch(交换机)需要经过特定配置才能支持802.3ad模式。



**xmit_hash_policy：**

在balance-xor和802.3ad模式下选择不同的hash模式，以用于slave选举。可能的取值有：

-  layer2 【缺省配置】

  使用硬件MAC地址的XOR来生成hash。公式为：

```
  (源MAC地址 XOR 目的MAC地址）% slave数目
```

  该算法会将某个网络对（network peer）上所有的流量全部分配到同一个slave上。

- layer3+4

   该策略在可能的时候使用上层协议的信息来生成hash。这将允许特定网络对（network peer）的流量分摊到多个slave上，尽管同一个连接（connection）不会分摊到多个slave上

  针对未分片的TCP和UDP包的计算公式为：

  ```
    ((源端口 XOR 目的端口) XOR ((源IP XOR 目的IP) AND 0xFFFF) % slave数目
  ```

  对于已分片TCP或UDP包，以及其他的IP包，源端口和目的端口的信息**被忽略了**；对于非IP流量，采用和layer2一样的hash策略。

  

  一个单一的TCP或UDP会话同时包含有分片和未分片的包将会导致包在两个接口上传递，这将会导致投递乱序。大多数流量不会满足这种条件，正如TCP很少分片，而大多数UDP流量不会在长期的会话中存在。其他的802.3ad实现有可能不能容忍这样的不适应性



##### 6、mode5: transmit load balancing (balance-tlb)

适配器传输负载均衡

**特点：**

​	不需要任何特别的switch(交换机)支持的通道bonding

**方式：**

- 在每个slave上根据当前的负载（依据速度）分配外出流量，接收时使用当前轮到的slave
- 如果正在接受数据的slave出故障了，另一个slave接管失败的slave的MAC地址

**条件：**

​	ethtool支持获取每个slave的速率

##### 7、mode6:adaptive load balancing (**balance-alb**)

适配器适应性负载均衡

此模式**包含了bond5的balance-tlb**，同时增加了针对IPV4流量的**接收负载均衡**

### 三、bonding参数介绍

| 参数                 | 说明                                                         |
| -------------------- | ------------------------------------------------------------ |
| **max_bonds**        | 为bonding驱动指定创建bonding设备的数量。比如，如果max_bonds为3，而且bonding驱动还没有加载，那么bond0，bond1，bond2将会被创建。缺省值为1。 |
| lacp_rate            | 指定在802.3ad模式下，我们希望的链接对端传输LACPDU包的速率。可能的选项：slow 或者 0 请求对端每30s传输LACPDUfast 或者 1 请求对端每1s传输LACPDU缺省值是slow |
| downdelay            | 指定一个时间，用于在发现链路故障后，等待一段时间然后禁止一个slave，单位是毫秒(ms)。该选项只对miimon监控有效。downdelay值应该是miimon值的整数倍，否则它将会被取整到最接近的整数倍。缺省值为0。 |
| arp_ip_target        | 指定一组IP地址用于ARP监控的目标，它只在arp_interval > 0时有效。这些IP地址是ARP请求发送的目标，用于判定到目标地址的链路是否工作正常。多个IP地址通过逗号分隔。至少指定一个IP地址。最多可以指定16个IP地址。缺省值是没有IP地址。 |
| arp_interval         | 指定ARP链路监控频率，单位是毫秒(ms)。如果APR监控工作于以太兼容模式（模式0和模式2）下，需要把switch(交换机)配置为在所有链路上均匀的分发网络包。如果switch(交换机)被配置为以XOR方式分发网络包，所有来自ARP目标的应答将会被同一个链路上的其他设备收到，这将会导致其他设备的失败。ARP监控不应该和miimon同时使用。设定为0将禁止ARP监控。缺省值为0。 |
| **miimon**           | 指定MII链路监控频率，单位是毫秒(ms)。这将决定驱动检查每个slave链路状态频率。0表示禁止MII链路监控。100可以作为一个很好的初始参考值。缺省值为0。 |
| **mode**             | 指定bonding的策略。缺省是balance-rr （round robin，轮询策略）。 |
| primary              | 指定哪个slave成为主设备（primary device），取值为字符串，如eth0，eth1等。只要指定的设备可用，它将一直是激活的slave。只有在主设备（primary device）断线时才会切换设备。这在希望某个slave设备优先使用的情形下很有用，比如，某个slave设备有更高的吞吐率。 primary选项只对active-backup模式有效。 |
| updelay              | 指定当发现一个链路恢复时，在激活该链路之前的等待时间，以毫秒计算。该选项只对miimon链路侦听有效。updelay应该是miimon值的整数倍，如果不是，它将会被向下取整到最近的整数。缺省值为0。 |
| use_carrier          | 指定miimon是否需要使用MII或者ETHTOOL ioctls还是netif_carrier_ok()来判定链路状态。MII或ETHTOOL ioctls更低效一些，而且使用了内核里废弃的旧调用序列；而netif_carrier_ok()依赖于设备驱动来维护状态（判断载波），在本文写作时，大多数但不是全部设备驱动支持这个特性。 如果bonding总是认为链路是通的，但实际上是断的，这有可能是由于你的网络设备驱动不支持netif_carrier_on/off。因为 netif_carrier的缺省状态是"carrier on"，因此如果驱动不支持netif_carrier，则会显示链路永远正常。在这种情况下，把use_carrier设为0，从而让bonding使用MII/ETHTOOL ictl来判定链路状态。 该选项设为1会使用netif_carrier_ok()，而设为0则会使用废弃的MII/ETHTOOL ioctls，缺省值是1。 |
| **xmit_hash_policy** | 查看上文中的介绍                                             |

### 四、绑定操作

1、拷贝配置文件

2、使用工具ifenslave 