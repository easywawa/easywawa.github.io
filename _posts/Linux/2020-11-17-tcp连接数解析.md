---
layout: post
category: Linux
title: TCP连接数解析
tagline: by 噜噜噜
tags: 
  - xx
published: true
---



<!--more-->

### 一、TCP连接数

1、tcp连接的标识方式：{local ip, local port,remote ip,remote port} 使用一个四元组来标识

2、tcp连接的方式：

​	Server 端，在某个固定端口监听，client主动发起连接，经过三路握手后建立tcp连接

​	Client端，client每次发起tcp连接请求时，除非绑定端口，通常会让系统选取一个空闲的本地端口（local port），该端口是独占的，不能和其他tcp连接共享。本地端口个数最大只有65536，端口0有特殊含义，不能使用，这样可用端口**最多只有65535**

3、单机最大连接数

​	Server端，server端tcp连接4元组中只有remote ip（也就是client ip）和remote port（客户端port）是可变的，因此最大tcp连接为客户端ip数×客户端port数，对IPV4，不考虑ip地址分类等因素，最大tcp连接数约为2的32次方（ip数）×2的16次方（port数），也就是server端单机最大tcp连接数约为**2的48次方**

​	Client端，上述已经说了最多65535

4、实际的tcp连接数	

​	上述给出的都是理论上的最大值，在实际情况中，会受到机器资源、操作系统等的限制，远远达不到理论值

   限制条件：**内存和文件描述符个数**【每个tcp连接都要占用一定内存，每个socket就是一个文件描述符，另外1024以下的端口通常为保留端口，经过试验，每个socket占用内存在15~20k之间】

5、影响一个socket占用内存的参数包括：

```
rmem_max

wmem_max

tcp_rmem

tcp_wmem

tcp_mem

grep skbuff /proc/slabinfo
```

对server端，通过增加内存、修改最大文件描述符个数等参数，单机最大并发TCP连接数超过10万 是没问题的，国外 Urban Airship 公司在产品环境中已做到 50 万并发 。在实际应用中，对大规模网络应用，还需要**考虑C10K 问题**



虽然现在的**集群，分布式技术**可以为我们将并发负载分担在多台服务器上，那我们只需要扩展出数十台电脑就可以解决问题，但是我们更希望能更大的挖掘单台服务器的资源，**先努力垂直扩展，再进行水平扩展**，这样可以有效的节省服务器相关的开支

### 二、文件句柄限制

每一个tcp连接都要占一个文件描述符，一旦这个文件描述符使用完了，新的连接到来返回给我们的错误是**“Socket/File:Can't open so many files”**

这时你需要明白操作系统对可以打开的最大文件数的限制。

##### 1、进程限制

- 执行 ulimit -n 输出 1024，说明对于一个进程而言最多只能打开1024个文件，所以你要采用此默认配置最多也就可以并发上千个TCP连接。

- 临时修改：ulimit -n 1000000，但是这种临时修改只对当前登录用户目前的使用环境有效，系统重启或用户退出后就会失效。

- 重启后失效的修改（不过我在CentOS 6.5下测试，重启后未发现失效）：编辑 /etc/security/limits.conf 文件， 修改后内容为

  `* soft nofile 1000000`

  `* hard nofile 1000000`

- 永久修改：编辑/etc/rc.local，在其后添加如下内容

  ulimit -SHn 1000000

##### 2、全局限制

- 执行 cat /proc/sys/fs/file-nr 输出 `9344 0 592026`，分别为：1.已经分配的文件句柄数，2.已经分配但没有使用的文件句柄数，3.最大文件句柄数。但在kernel 2.6版本中第二项的值总为0，这并不是一个错误，它实际上意味着已经分配的文件描述符无一浪费的都已经被使用了 。

  ```
  [root@ansible-2 ipv4]# cat /proc/sys/fs/file-nr
  2432    0       381955
  ```

- 我们可以把这个数值改大些，用 root 权限修改 /etc/sysctl.conf 文件:

  `fs.file-max = 1000000`

  `net.ipv4.ip_conntrack_max = 1000000`

  `net.ipv4.netfilter.ip_conntrack_max = 1000000`

  ### 三、总结

  1、其实65535这个数字，只是决定了服务器端最多可以拥有65535个Bind的Socket。也就是说，最多可以开65535个服务器进程，但是你要知道这个能够连接客户端的数量没有任何关系，Accept过来的Socket是不需要Bind任何IP地址的，也没有端口占用这一说。作为Server端的Socket本身只负责监听和接受连接操作

  2、千万不要误以为1个server只允许连接65535个Client。记住，**TCP连出受端口限制,连入仅受内存限制**

  3、上面给出的结论都是理论上的单机TCP并发连接数，实际上单机并发连接数肯定要受硬件资源（内存）、网络资源（带宽）的限制

  4、想让1个server并发高效得连接几万个Client，需要使用IOCP“**完成端口(Completion Port**)”的技术

  http://blog.csdn.net/libaineu2004/article/details/40087167

  ### 四、常见设置

  ##### 1、修改用户**进程**可打开文件数限制（注意：是进程限制的）

  最高的并发数量都要受到系统对用户单一进程同时可打开文件数量的限制(这是因为系统为每个TCP连接都要创建一个socket句柄，每个socket句柄同时也是一个文件句柄)。可使用ulimit命令查看系统允许当前用户进程打开的文件数限制：

  ```
  [speng@as4 ~]$ ulimit -n
  1024
  ```

  这表示当前用户的每个进程最多允许同时打开1024个文件，这1024个文件中还得除去每个进程必然打开的标准输入，标准输出，标准错误，服务器监听 socket，进程间通讯的unix域socket等文件，那么剩下的可用于客户端socket连接的文件数就只有大概1024-10=1014个左右。**也就是说缺省情况下，基于Linux的通讯程序最多允许同时1014个TCP并发连接**

  

  想支持更高数量的TCP并发连接的通讯处理程序，就必须修改Linux对当前用户的进程同时打开的文件数量的**软限制(soft limit)和硬限制(hard limit)**

  软限制：指Linux在当前系统能够承受的范围内进一步限制用户同时打开的文件数

  硬限制：根据系统硬件资源状况(主要是内存)计算出来的系统最多可同时打开的文件数量

  

  ①临时设置：

  ```
  ulimit -n <数字>
  ```

  如果系统回显类似于“Operation notpermitted”之类的话，说明上述限制修改失败，实际上是因为在中指定的数值超过了Linux系统对该用户打开文件数的软限制或硬限制

  ②修改/etc/security/limits.conf文件

  ```
  speng soft nofile 10240
  speng hard nofile 10240
  root soft nofile 65535
  root hard nofile 65535
  * soft nofile 65535
  * hard nofile 6553
  ```

  其中speng指定了要修改哪个用户的打开文件数限制，可用’*'号表示修改所有用户的限制；soft或hard指定要修改软限制还是硬限制；10240则指定了想要修改的新的限制值，即最大打开文件数(请注意软限制值要小于或等于硬限制)。修改完后保存文件

  

  ③修改/etc/pam.d/login文件，在文件中添加如下行

  ```
  session required /lib/security/pam_limits.so
  ```

  这是告诉Linux在用户完成系统登录后，应该调用pam_limits.so模块来设置系统对该用户可使用的各种资源数量的最大限制(包括用户可打开的最大文件数限制)，而pam_limits.so模块就会从/etc/security/limits.conf文件中读取配置来设置这些限制值。修改完后保存此文件

  

  ④查看Linux系统级的最大打开文件数限制

  ```
  [speng@as4 ~]$ cat /proc/sys/fs/file-max
  381947
  ```

  这表明这台Linux系统最多允许同时打开(即包含所有用户打开文件数总和)12158个文件，**是Linux系统级硬限制**，所有用户级的打开文件数限制都不应超过这个数值。通常这个系统级硬限制是Linux系统在启动时根据系统硬件资源状况计算出来的最佳的最大同时打开文件数限制，如果没有特殊需要，不应该修改此限制，除非想为用户级打开文件数限制设置超过此限制的值。修改此硬限制的方法是修改/etc/rc.local脚本，在脚本中添加如下行：

  ```
  echo 22158 > /proc/sys/fs/file-max
  ```

  

  ##### 2、修改网络内核对TCP连接的有关限制

  对于tpc客户端来说的

  **第一种情况，端口限制**

  ①查看当前默认的端口范围

  ```
  cat /proc/sys/net/ipv4/ip_local_port_range
  32768   60999
  ```

  ②修改/etc/sysctl.conf文件，在文件中添加如下行

  ```
  net.ipv4.ip_local_port_range = 1024 65000
  ```

  这表明将系统对本地端口范围限制设置为1024~65000之间。请注意，本地端口范围的最小值必须大于或等于1024；而端口范围的最大值则应小于或等于65535。修改完后保存此文件

  执行sysctl命令

  ```
  sysctl -p
  ```

  

  **第二种情况，追踪数限制** 【具体可查看conntrack一节】

  ①修改/etc/sysctl.conf文件，在文件中添加如下行

  ```
  net.ipv4.ip_conntrack_max = 10240
  ```

  ②执行sysctl命令 

  ```
  sysctl -p
  ```

  

  ##### 3、使用支持高并发网络I/O的编程技术

  在Linux上编写高并发TCP连接应用程序时，必须使用合适的网络I/O技术和I/O事件分派机制

  在开发支持高并发TCP连接的Linux应用程序时，**应尽量使用epoll或AIO技术**来实现并发的TCP连接上的I/O控制，这将为提升程序对高并发TCP连接的支持提供有效的I/O保证

  

  ### 五、C10k的问题

  具体参考另一篇文章https://blog.csdn.net/wangtaomtk/article/details/51811011

  

  