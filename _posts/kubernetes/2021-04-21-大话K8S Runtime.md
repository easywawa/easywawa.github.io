---
layout: post
category: kubernetes
title: 大话K8S runtime
tagline: by 噜噜噜
tags: 
  - xx
published: true
---



<!--more-->

转载于：https://mp.weixin.qq.com/s/s9i2mkiFc3_qAUhurYdZKQ

### 一、概念

docker、rkt、containerd、cri-o、kata、gvisor、containerd-shim、dockershim等

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy84WkZ6clJqcWF0b0I5ekVDQjVEMUZVUFJTVExnbWhsaWFYSGVmNVJ0amhxRFZscVdsaWFRTnhpYkFMVklGTHRXajN4anNOZ3pFN2p3bndXUmhHUTJReDBkUS82NDA?x-oss-process=image/format,png)

### 二、最常见的Runtime方案docker

![](https://mmbiz.qpic.cn/mmbiz_jpg/1e9ia4YcKpMP86jcyoUAn4jOjP1g6q0eVVsWA6sFFchBztWkSOa8S9yXxwDA2N0rBZ4DtIKRzOnFD5ibXM2aNjzA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### 1、kubelet创建容器的过程

① kubelet 通过CRI接口（一组gRPC接口）调用dockershim，请求创建一个容器。[该过程中kubelet可视作一个简单的CRI Client，而dockershim 就是接受请求的Server。目前dockershim的代码是内嵌在kubelet中，所以接收调用的就是kubelet进程]

② dockershim 收到请求后，它会转化成 Docker Daemon 能听懂的请求，发到 Docker Daemon 上，并请求创建一个容器

③ Docker Daemon 早在 1.12 版本中就已经将针**对容器的操作**移到**另一个守护进程 containerd 中**了。因此 Docker Daemon 仍然不能帮人们创建容器，而是需要**请求 containerd** 创建一个容器

④ containerd 收到请求后，并不会自己直接去操作容器，而是创建一个叫做 containerd-shim 的进程，让 containerd-shim 去操作容器。

⑤ **containerd-shim 在这一步需要调用 runc 这个命令行工具**，来启动容器;

⑥ runc 启动完容器后，它会直接退出，containerd-shim 则会成为容器进程的父进程，负责收集容器进程的状态，上报给 containerd。并在容器中 pid 为 1 的进程退出后接管容器中的子进程，然后进行清理，确保不会出现僵尸进程



疑问：Docker Daemon 和 dockershim 看上去就像是两个不干活的组件，Kubelet 为啥不直接调用 containerd 呢?

**答案：当然是可以的**



#### 2、容器历史

① 最开始的k8s架构

```
kubelet--------------> Docker Daemon------------->libcontainer库 
```

② 政治需求，不能让docker一家控制，推出了**OCI**标准。

此标准中规定了两点：容器镜像的标准、容器需要能接收哪些指令

​	这时候其他公司就推出了自己的引擎，如rkt

③ docker公司将libcontainer库封装起来**变成runc**，**作为OCI的参考实现**

但是这时候问题来了，k8s需要对接这么多的容器引擎吗？那还不累死k8s的工作人员

④ kubernetes v1.5版本推出了**CRI机制**（即容器运行时接口，Container Runtime Interface），告诉大家你们**只要实现这个接口都可以做Runtime**

  **这时候就有了shim(垫片)，作为适配器将各种容器运行时本身的接口和CRI的接口进行适配**，如dockershim



接着看docker公司的历史决策：

① 上面说到docker将runc贡献出来作为OCI的参考，后面想自己搞一个容器编排平台swam

②  为了进军paas市场，将docker架构做了切分，**将容器操作都移动到单独的进程containerd中**【一个runtime】，而Docker Daemon只负责上层的封装编排。

③  进军失败之后，Docker公司将containerd项目捐献给了CNCF。



尽管现在已经有 CRI-O、containerd-plugin 这样更精简轻量的 Runtime 架构，但是 **dockershim 这一套作为经受了最多生产环境考验的方案，迄今为止仍是 Kubernetes 默认的 Runtime 实现。**

### 三、OCI、CRI、与被滥用的名词“Runtime”

#### 1、OCI

也就是开放容器标准，上面已经说过规定了两点：

​	**容器镜像应该是什么样的，即 ImageSpec。**它大致规定的是，你的容器镜像需要是一个压缩了的文件夹，文件夹里以 xxx 结构放入 xxx 文件中；

   **容器要需要能接收哪些指令，这些指令的行为是什么，即 RuntimeSpec。**简单来说，它规定的就是“容器”要能够执行“create”“start”“stop”“delete”这些命令，并且行为要规范。



实现此标准的项目：**runc**、**Kata**（以及它的前身 runV 和 Clear Containers）、**gVisor**。其它比较偏门的还有 Rust 写的 railcar；

#### 2、CRI

就是一组gRPC接口

- 一套针对容器操作的接口，包括创建、启停容器等；
- 一套针对镜像操作的接口，包括拉取镜像、删除镜像等；
- 还有一套针对 PodSandbox（容器沙箱环境）的操作接口。



实现此标准的项目: **Docker（借助 dockershim）**、**containerd（借助 CRI-containerd）**、**CRI-O**、frakti 等

#### 3、Runtime

**通过这个粗略的分类，就可以总结出整个 Runtime 架构万变不离其宗的三层抽象：**

```
Orchestration API -> Container API -> Kernel API
```

这其中 Kubernetes 已经是 Orchestration API 的事实标准。而在 Kubernetes 中，Container API 的接口标准就是 CRI，由 cri-runtime 实现。Kernel API 的规范是 OCI，由 oci-runtime 实现



### 四、containerd、CRI-O的实现和强隔离容器

目前在k8s官网上支持这三种方案 docker、containerd、CRI-O

https://kubernetes.io/zh/docs/setup/production-environment/container-runtimes/

#### 1、containerd、CRI-O

除了 Kubernetes 之外，containerd 还要接诸如 Swarm 等调度系统，因此它不会去直接实现 CRI。这个适配工作就要交给一个 shim 了

在 containerd v1.0 中，对 CRI 的适配通过一个单独的进程`CRI-containerd`来完成：

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/1e9ia4YcKpMPibqpjvBxmRrRMl8FcBicPlSPu7tZee12Ix1Z6bHGVElU90rddTNYWOygiaxYt1icqrSEBHBibu2dJplA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

**containerd v1.1 中做的又更漂亮一点，砍掉 CRI-containerd 进程，直接把适配逻辑作为插件放进 containerd 主进程中：**

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/1e9ia4YcKpMPibqpjvBxmRrRMl8FcBicPlS4IC2jQ6ez1nCyjF9iapMCTApUnJkJPeV8CyRrGYoJkUhBgRhzpRnrqQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

**但在 containerd 做这些事情之前，社区就已经有了一个更为专注的 cri-runtime: CRI-O。它非常纯粹，可以兼容 CRI 和 OCI，做一个 Kubernetes 专用的运行时：**

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/1e9ia4YcKpMPibqpjvBxmRrRMl8FcBicPlSNYhHXqiae4l0icFS5FHbn92WrXibicMuVO218AMbJjec7HumPwgC92S4vw/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)



其中`conmon`就对应 containerd-shim，大体意图是一样的

CRI-O 和 containerd（直接调用）的方案比起默认的 dockershim 简洁很多，但没什么生产环境的验证案例。本人所知道的仅仅是 containerd 在 GKE 上是 beta 状态。因此假如你对 Docker 没有特殊的政治恨意，大可不必把 dockershim 这套换掉



#### 2、强隔离容器

**Kata、gVisor、firecracker**

为了解决kubernetes的隔离性差的问题：

- ​		kube-apiserver 是整个集群中的单例，并且没有多租户概念
- ​	    默认的 oci-runtime 是 runc，而 runc 启动的容器是共享内核的



Kata 的一张图很好地解释了**基于虚拟机的容器**与基于 namespaces 和 Cgroups 的容器间的区别：

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/1e9ia4YcKpMPibqpjvBxmRrRMl8FcBicPlS3L78D7GPV4DmJvOYc3wAWPMp6ZbrQdjJMxicQcRahficiabrXgPHR0rxw/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)	

**Kata 告诉你，虚拟机没那么邪恶，只是以前没玩好：**

- **不好管理**是因为没有遵循“不可变基础设施”，以前大家都在虚拟机上疯狂的试探。这台装 Java 8，那台装 Java 6，Admin 是要 angry 的。现在，Kata 则支持 OCI 镜像，完全可以用上 Dockerfile + 镜像，让不好管理成为了过去时；
- **笨重**是因为之前要虚拟化整个系统。现在我们只着眼于虚拟化应用，那就可以裁剪掉很多功能，把 VM 做得很轻量。因此即便用虚拟机来做容器，Kata 还是可以将容器启动时间压缩得非常短，启动后在内存上和 IO 上的 overhead 也尽可能去优化。



Kubernetes 上的调度单位是 Pod，是容器组，Kata 虚拟机里的一个容器。那同一个 Pod 间的容器应该如何做 namespace 的共享？

 分析下现在的架构方式，每次 Kubelet 在创建 Pod 时，就会先调用 CRI 的`RunPodSandbox`接口启动一个沙箱环境，再调用`CreateContainer`在沙箱中创建的容器

那么对于 Kata Container 而言，只要在`RunPodSandbox`调用中创建一个 VM，之后再往 VM 中添加容器就可以了。

**虚拟机类似与现在的沙箱**

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/1e9ia4YcKpMPibqpjvBxmRrRMl8FcBicPlSic2ibeia66m3qabYmHn4rGRsugwAVGdSicY1xFhDh8XesKUUCwBlz9IDTg/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

**说完了 Kata，其实 gVisor 和 firecracker 都不言自明了，大体上都是类似的，只是：**

- gVisor 并不会去创建一个完整的 VM，而是实现了一个叫“Sentry”的用户态进程来处理容器的 syscall，而拦截 syscall 并重定向到 Sentry 的过程则由 KVM 或 ptrace 实现；
- firecracker 称自己为 microVM，即轻量级虚拟机，它本身还是基于 KVM 的。不过 KVM 通常使用 QEMU 来虚拟化除 CPU 和内存外的资源，比如 IO 设备、网络设备。firecracker 则使用 rust 实现了最精简的设备虚拟化，为的就是压榨虚拟化的开销，越轻量越好。